# Исследование подходов разных подходов дообучения для решения задачи cross-lingual extractive QA

_Итоговый проект по курсу "Автоматическая обработка естественного языка"._

_Автор проекта: Новоселова Анна Дмитриевна БКЛ221_

***

Целью проекта является исследование и сравнение вариантов решения задачи cross-lingual extractive question answering путём различных стратегий дообучения.
В частности, рассматриваются следующие три подхода:
1. Zero-shot — дообучение модели на английском датасете, созданном путём ручной разметки, и тестирование zero-shot на данных второго языка (в нашем случае испанского).
2. Translate-train — дообучение модели на датасете, который был автоматически переведён с английского на целевой (испанский) язык. Мотивацией для такого подхода служит тот факт, что создание подобных синтетических датасетов дешевле ручной разметки, что может оказаться крайне полезно для создания многоязычной QA-систем, так как хороших обучающих датасетов, созданных людьми, не так уж много для различных языков.
3. Mixed-language fine-tuning — дообучение модели сразу на нескольких языках (в нашем эксперименте мы ограничиваемся английским и испанским). Мы проверяем, как такой подход влияет на качество QA, когда модель знакома не с одним языком в рамках этой конкретной задачи, а также дополнительно смотрим, способна ли модель переносить знания на третий язык (в рамках этого проекта был взят немецкий).

В ```fine-tuning and evaluation.ipynb``` описаны детали реализации каждой стратегии fine-tuning'а, а также приведены и описаны результаты инференса по тестовым выборкам.
